import numpy as np, pandas as pd
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,
                             roc_auc_score, roc_curve, precision_recall_fscore_support,
                             classification_report)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
import shap, warnings; warnings.filterwarnings("ignore")
RANDOM_STATE = 42

df = pd.read_csv(r'C:\\Users\\SISTEMAS\\Documents\\PYTHON\\DATA\\data.csv', sep=';')
print(df.head())

# Resumen para el informe
resumen_cols = pd.DataFrame({
    "tipo": df.dtypes.astype(str),
    "nulos": df.isna().sum(),
    "%_nulos": (df.isna().mean()*100).round(2)
})
resumen_cols.head(20)


# Target original: {'Dropout','Enrolled','Graduate'} → convertir a binario
df["target_bin"] = (df["Target"] == "Dropout").astype(int)

id_cols = [c for c in df.columns if c.lower() in ["id","student_id"]]
X = df.drop(columns=["Target","target_bin"] + id_cols, errors="ignore")
y = df["target_bin"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE
)
y_train.mean(), y_test.mean()  # proporción de desertores


num_cols = X_train.select_dtypes(include=np.number).columns.tolist()
cat_cols = X_train.select_dtypes(exclude=np.number).columns.tolist()

preproc = ColumnTransformer([
    ("num", StandardScaler(), num_cols),
    ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols)
])

def make_pipe(estimator):
    return ImbPipeline([
        ("prep", preproc),
        ("smote", SMOTE(random_state=RANDOM_STATE)),
        ("clf", estimator),
    ])


models = {
    "LogReg": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),
    "RF": RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=RANDOM_STATE),
    "SVM": SVC(kernel="rbf", probability=True, random_state=RANDOM_STATE),
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)

rows = []
for name, est in models.items():
    pipe = make_pipe(est)
    auc = cross_val_score(pipe, X_train, y_train, cv=cv, scoring="roc_auc", n_jobs=-1)
    f1  = cross_val_score(pipe, X_train, y_train, cv=cv, scoring="f1", n_jobs=-1)
    rows.append([name, auc.mean(), auc.std(), f1.mean(), f1.std()])

bench = pd.DataFrame(rows, columns=["Modelo","AUC_mean","AUC_std","F1_mean","F1_std"])\
         .sort_values("AUC_mean", ascending=False)
bench


best_name = bench.iloc[0,0]
best_est  = models[best_name]
best_pipe = make_pipe(best_est).fit(X_train, y_train)

proba = best_pipe.predict_proba(X_test)[:,1]
pred  = (proba >= 0.5).astype(int)

auc = roc_auc_score(y_test, proba)
prec, rec, f1, _ = precision_recall_fscore_support(y_test, pred, average="binary")
print(f"{best_name} | AUC={auc:.3f} | Precision={prec:.3f} | Recall={rec:.3f} | F1={f1:.3f}")

print("\nClassification report:")
print(classification_report(y_test, pred, digits=3))

cm = confusion_matrix(y_test, pred)
ConfusionMatrixDisplay(cm).plot(cmap="Blues"); plt.title("Matriz de confusión"); plt.show()

fpr, tpr, _ = roc_curve(y_test, proba)
plt.plot(fpr, tpr, label=f"{best_name} (AUC={auc:.3f})")
plt.plot([0,1],[0,1],'k--'); plt.xlabel("FPR"); plt.ylabel("TPR")
plt.title("Curva ROC"); plt.legend(); plt.grid(True); plt.show()


# Importancias (si el modelo las tiene, p.ej. RandomForest)
try:
    ohe = best_pipe.named_steps["prep"].named_transformers_["cat"]
    cat_names = ohe.get_feature_names_out(cat_cols) if len(cat_cols)>0 else []
    feat_names = np.r_[num_cols, cat_names]

    if hasattr(best_pipe.named_steps["clf"], "feature_importances_"):
        imp = best_pipe.named_steps["clf"].feature_importances_
        fi = pd.DataFrame({"feature": feat_names, "importance": imp})\
             .sort_values("importance", ascending=False).head(20)
        sns.barplot(x="importance", y="feature", data=fi); plt.title("Top 20 variables"); plt.show()
except Exception as e:
    print("Importancias no disponibles:", e)

# SHAP (opcional)
try:
    explainer = shap.Explainer(best_pipe.predict_proba, X_train)
    shap_values = explainer(X_test.sample(min(200, len(X_test)), random_state=RANDOM_STATE))
    shap.plots.beeswarm(shap_values, max_display=15)
except Exception as e:
    print("SHAP no disponible:", e)

param_grid = {
    "clf__n_estimators": [300, 500],
    "clf__max_depth": [None, 10, 20],
}
grid = GridSearchCV(make_pipe(RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)),
                    param_grid, scoring="roc_auc", cv=cv, n_jobs=-1, verbose=1)
grid.fit(X_train, y_train)
grid.best_params_, grid.best_score_
best_pipe = grid.best_estimator_

import joblib, os
os.makedirs("artifacts", exist_ok=True)
joblib.dump(best_pipe, "artifacts/modelo_desercion.pkl")
bench.to_csv("artifacts/benchmark_modelos.csv", index=False)
resumen_cols.to_csv("artifacts/resumen_variables.csv")
